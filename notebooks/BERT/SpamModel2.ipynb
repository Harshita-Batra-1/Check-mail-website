{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "df = pd.read_csv('/content/spam_ham_dataset.csv') \n",
        "df.drop(df.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "def clean_str(string, reg = RegexpTokenizer(r'[a-z]+')): \n",
        "    # Clean a string with RegexpTokenizer\n",
        "    string = string.lower() \n",
        "    tokens = reg.tokenize(string) \n",
        "    return \" \".join(tokens) \n",
        "df['text_clean'] = df['text'].apply(lambda string: clean_str(string))\n",
        "df_spam = df[df['label']=='spam']\n",
        "df_ham = df[df['label']=='ham'] \n",
        "df_ham_downsampled = df_ham.sample(df_spam.shape[0])\n",
        "df_balanced = pd.concat([df_ham_downsampled, df_spam])\n",
        "df_balanced.drop(['text'], axis=1,inplace=True)\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(df_balanced['text_clean'],df_balanced['label_num'], stratify=df_balanced['label_num'])\n",
        "import tensorflow as tf \n",
        "import tensorflow_hub as hub \n",
        "!pip install -U tensorflow-text==2.6.0 \n",
        "import tensorflow_text as text \n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
        "# building sequencial model # Bert layers \n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "# Neural network layers \n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output']) \n",
        "#DropoutLayer - Dropout Regularization - some might beb biased with input features toh overfiiting remove\n",
        "#pooledEncoding-shape-no. of txt, words,word embedding vector size\n",
        "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "# Use inputs and outputs to construct a final model\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [l])\n",
        "METRICS = [ \n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "] \n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy', \n",
        "              metrics=METRICS) \n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "mc=ModelCheckpoint(filepath=\"/content/saved_model/best_model.h5\", # Where best file will be saved\n",
        "                                              # best model would go here\n",
        "                   monitor=\"accuracy\",\n",
        "                   verbose=1, \n",
        "                   save_best_only=True) \n",
        "es=EarlyStopping(monitor=\"accuracy\", \n",
        "                 min_delta=0.01, \n",
        "                 patience=5, # No of time it should wait if accuracy doesnt increase\n",
        "                 verbose=1)\n",
        "cb=[mc,es]\n",
        "model.fit(X_train, y_train, epochs=30,callbacks=cb)"
      ],
      "metadata": {
        "id": "OpVnh9-SFghJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2c1735-3792-47e1-a3db-566f155e160c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-text==2.6.0 in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: tensorflow<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.6.0) (2.6.5+zzzcolab20220523104206)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.6.0) (0.12.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.17.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2.6.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.37.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.48.1)\n",
            "Requirement already satisfied: typing-extensions<3.11,>=3.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.15.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.1.0)\n",
            "Requirement already satisfied: keras<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.2.0)\n",
            "Epoch 1/30\n",
            "71/71 [==============================] - 892s 12s/step - loss: 0.6396 - accuracy: 0.6250 - precision: 0.6188 - recall: 0.6512\n",
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.62500, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 2/30\n",
            "71/71 [==============================] - 874s 12s/step - loss: 0.5759 - accuracy: 0.6899 - precision: 0.6993 - recall: 0.6664\n",
            "\n",
            "Epoch 00002: accuracy improved from 0.62500 to 0.68995, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 3/30\n",
            "71/71 [==============================] - 873s 12s/step - loss: 0.5343 - accuracy: 0.7469 - precision: 0.7520 - recall: 0.7367\n",
            "\n",
            "Epoch 00003: accuracy improved from 0.68995 to 0.74689, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 4/30\n",
            "71/71 [==============================] - 878s 12s/step - loss: 0.5053 - accuracy: 0.7745 - precision: 0.7777 - recall: 0.7687\n",
            "\n",
            "Epoch 00004: accuracy improved from 0.74689 to 0.77447, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 5/30\n",
            "71/71 [==============================] - 872s 12s/step - loss: 0.4743 - accuracy: 0.8016 - precision: 0.8133 - recall: 0.7829\n",
            "\n",
            "Epoch 00005: accuracy improved from 0.77447 to 0.80160, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 6/30\n",
            "71/71 [==============================] - 876s 12s/step - loss: 0.4574 - accuracy: 0.8101 - precision: 0.8126 - recall: 0.8060\n",
            "\n",
            "Epoch 00006: accuracy improved from 0.80160 to 0.81005, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 7/30\n",
            "71/71 [==============================] - 880s 12s/step - loss: 0.4381 - accuracy: 0.8310 - precision: 0.8292 - recall: 0.8336\n",
            "\n",
            "Epoch 00007: accuracy improved from 0.81005 to 0.83096, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 8/30\n",
            "71/71 [==============================] - 876s 12s/step - loss: 0.4180 - accuracy: 0.8430 - precision: 0.8396 - recall: 0.8479\n",
            "\n",
            "Epoch 00008: accuracy improved from 0.83096 to 0.84297, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 9/30\n",
            "71/71 [==============================] - 880s 12s/step - loss: 0.4014 - accuracy: 0.8501 - precision: 0.8529 - recall: 0.8461\n",
            "\n",
            "Epoch 00009: accuracy improved from 0.84297 to 0.85009, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 10/30\n",
            "71/71 [==============================] - 879s 12s/step - loss: 0.3901 - accuracy: 0.8492 - precision: 0.8508 - recall: 0.8470\n",
            "\n",
            "Epoch 00010: accuracy did not improve from 0.85009\n",
            "Epoch 11/30\n",
            "71/71 [==============================] - 869s 12s/step - loss: 0.3774 - accuracy: 0.8625 - precision: 0.8622 - recall: 0.8630\n",
            "\n",
            "Epoch 00011: accuracy improved from 0.85009 to 0.86254, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 12/30\n",
            "71/71 [==============================] - 881s 12s/step - loss: 0.3684 - accuracy: 0.8652 - precision: 0.8642 - recall: 0.8665\n",
            "\n",
            "Epoch 00012: accuracy improved from 0.86254 to 0.86521, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 13/30\n",
            "71/71 [==============================] - 874s 12s/step - loss: 0.3576 - accuracy: 0.8719 - precision: 0.8725 - recall: 0.8710\n",
            "\n",
            "Epoch 00013: accuracy improved from 0.86521 to 0.87189, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 14/30\n",
            "71/71 [==============================] - 864s 12s/step - loss: 0.3449 - accuracy: 0.8763 - precision: 0.8757 - recall: 0.8772\n",
            "\n",
            "Epoch 00014: accuracy improved from 0.87189 to 0.87633, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 15/30\n",
            "71/71 [==============================] - 918s 13s/step - loss: 0.3426 - accuracy: 0.8772 - precision: 0.8746 - recall: 0.8808\n",
            "\n",
            "Epoch 00015: accuracy improved from 0.87633 to 0.87722, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 16/30\n",
            "71/71 [==============================] - 897s 13s/step - loss: 0.3345 - accuracy: 0.8790 - precision: 0.8737 - recall: 0.8861\n",
            "\n",
            "Epoch 00016: accuracy improved from 0.87722 to 0.87900, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 17/30\n",
            "71/71 [==============================] - 886s 12s/step - loss: 0.3227 - accuracy: 0.8892 - precision: 0.8861 - recall: 0.8932\n",
            "\n",
            "Epoch 00017: accuracy improved from 0.87900 to 0.88923, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 18/30\n",
            "71/71 [==============================] - 864s 12s/step - loss: 0.3214 - accuracy: 0.8812 - precision: 0.8762 - recall: 0.8879\n",
            "\n",
            "Epoch 00018: accuracy did not improve from 0.88923\n",
            "Epoch 19/30\n",
            "71/71 [==============================] - 875s 12s/step - loss: 0.3164 - accuracy: 0.8843 - precision: 0.8803 - recall: 0.8897\n",
            "\n",
            "Epoch 00019: accuracy did not improve from 0.88923\n",
            "Epoch 20/30\n",
            "71/71 [==============================] - 862s 12s/step - loss: 0.3084 - accuracy: 0.8964 - precision: 0.8884 - recall: 0.9066\n",
            "\n",
            "Epoch 00020: accuracy improved from 0.88923 to 0.89635, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 21/30\n",
            "71/71 [==============================] - 872s 12s/step - loss: 0.2989 - accuracy: 0.8932 - precision: 0.8932 - recall: 0.8932\n",
            "\n",
            "Epoch 00021: accuracy did not improve from 0.89635\n",
            "Epoch 22/30\n",
            "71/71 [==============================] - 866s 12s/step - loss: 0.2939 - accuracy: 0.8968 - precision: 0.8892 - recall: 0.9066\n",
            "\n",
            "Epoch 00022: accuracy improved from 0.89635 to 0.89680, saving model to /content/saved_model/best_model.h5\n",
            "Epoch 00022: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUCjNAvMgj1k",
        "outputId": "07a3dc7d-ce4b-40b9-ada9-fc9e1e3a279f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 297s 12s/step - loss: 0.2727 - accuracy: 0.9173 - precision: 0.9563 - recall: 0.8747\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2726881802082062, 0.9173333048820496, 0.9562682509422302, 0.874666690826416]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "y_predicted "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf9lY6hzhbRm",
        "outputId": "462cc13f-0e38-4071-9ea8-d67bd291d575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8977351 ],\n",
              "       [0.9648032 ],\n",
              "       [0.24423906],\n",
              "       [0.09989417],\n",
              "       [0.5119101 ],\n",
              "       [0.0125874 ],\n",
              "       [0.91329   ],\n",
              "       [0.57473534],\n",
              "       [0.5875761 ],\n",
              "       [0.8790566 ],\n",
              "       [0.34818852],\n",
              "       [0.7017441 ],\n",
              "       [0.92723805],\n",
              "       [0.3718269 ],\n",
              "       [0.1117624 ],\n",
              "       [0.10903108],\n",
              "       [0.6848657 ],\n",
              "       [0.96549946],\n",
              "       [0.95561606],\n",
              "       [0.6706395 ],\n",
              "       [0.02034804],\n",
              "       [0.08365983],\n",
              "       [0.04314968],\n",
              "       [0.8188089 ],\n",
              "       [0.10134268],\n",
              "       [0.05907387],\n",
              "       [0.86684626],\n",
              "       [0.12478039],\n",
              "       [0.04052982],\n",
              "       [0.02739891],\n",
              "       [0.04906222],\n",
              "       [0.07826823],\n",
              "       [0.97009426],\n",
              "       [0.07033205],\n",
              "       [0.10280964],\n",
              "       [0.2905305 ],\n",
              "       [0.2626843 ],\n",
              "       [0.5709429 ],\n",
              "       [0.52675796],\n",
              "       [0.06817579],\n",
              "       [0.11778811],\n",
              "       [0.9802563 ],\n",
              "       [0.9351923 ],\n",
              "       [0.12493089],\n",
              "       [0.2117132 ],\n",
              "       [0.7470538 ],\n",
              "       [0.08679736],\n",
              "       [0.8258853 ],\n",
              "       [0.06689945],\n",
              "       [0.07735839],\n",
              "       [0.4501024 ],\n",
              "       [0.08908314],\n",
              "       [0.06451255],\n",
              "       [0.8250764 ],\n",
              "       [0.78217584],\n",
              "       [0.59462726],\n",
              "       [0.09485453],\n",
              "       [0.22656748],\n",
              "       [0.9516485 ],\n",
              "       [0.5363395 ],\n",
              "       [0.4777041 ],\n",
              "       [0.3736386 ],\n",
              "       [0.5515265 ],\n",
              "       [0.63799655],\n",
              "       [0.12151706],\n",
              "       [0.03191319],\n",
              "       [0.04685163],\n",
              "       [0.93154883],\n",
              "       [0.37909806],\n",
              "       [0.9617157 ],\n",
              "       [0.03153765],\n",
              "       [0.71562284],\n",
              "       [0.09802091],\n",
              "       [0.7900953 ],\n",
              "       [0.93311584],\n",
              "       [0.598724  ],\n",
              "       [0.13483045],\n",
              "       [0.10295779],\n",
              "       [0.05512205],\n",
              "       [0.37496674],\n",
              "       [0.6695311 ],\n",
              "       [0.77065206],\n",
              "       [0.28049943],\n",
              "       [0.88602805],\n",
              "       [0.08931956],\n",
              "       [0.02713448],\n",
              "       [0.01717907],\n",
              "       [0.7060692 ],\n",
              "       [0.8732085 ],\n",
              "       [0.4754979 ],\n",
              "       [0.06817579],\n",
              "       [0.19286174],\n",
              "       [0.40810966],\n",
              "       [0.9075296 ],\n",
              "       [0.06407648],\n",
              "       [0.5999477 ],\n",
              "       [0.10846981],\n",
              "       [0.92857844],\n",
              "       [0.06011164],\n",
              "       [0.21751279],\n",
              "       [0.04045382],\n",
              "       [0.86747074],\n",
              "       [0.25544775],\n",
              "       [0.9401639 ],\n",
              "       [0.35727483],\n",
              "       [0.9279768 ],\n",
              "       [0.24833623],\n",
              "       [0.92624265],\n",
              "       [0.08430913],\n",
              "       [0.79590034],\n",
              "       [0.8456685 ],\n",
              "       [0.05005822],\n",
              "       [0.04785144],\n",
              "       [0.34470809],\n",
              "       [0.04122329],\n",
              "       [0.83454067],\n",
              "       [0.14037925],\n",
              "       [0.06724253],\n",
              "       [0.6742507 ],\n",
              "       [0.2090537 ],\n",
              "       [0.39031002],\n",
              "       [0.1015611 ],\n",
              "       [0.9676331 ],\n",
              "       [0.07960746],\n",
              "       [0.98775804],\n",
              "       [0.9473032 ],\n",
              "       [0.68178356],\n",
              "       [0.5756096 ],\n",
              "       [0.09072912],\n",
              "       [0.66226673],\n",
              "       [0.7356049 ],\n",
              "       [0.2732507 ],\n",
              "       [0.09615126],\n",
              "       [0.10593182],\n",
              "       [0.8191388 ],\n",
              "       [0.06614104],\n",
              "       [0.68303   ],\n",
              "       [0.94858205],\n",
              "       [0.14724296],\n",
              "       [0.163001  ],\n",
              "       [0.6379197 ],\n",
              "       [0.1236605 ],\n",
              "       [0.08391228],\n",
              "       [0.7193365 ],\n",
              "       [0.7583243 ],\n",
              "       [0.6843071 ],\n",
              "       [0.0388076 ],\n",
              "       [0.12586531],\n",
              "       [0.8330636 ],\n",
              "       [0.72818816],\n",
              "       [0.8544141 ],\n",
              "       [0.19046557],\n",
              "       [0.0517469 ],\n",
              "       [0.11301345],\n",
              "       [0.10232183],\n",
              "       [0.07677886],\n",
              "       [0.70498824],\n",
              "       [0.5271883 ],\n",
              "       [0.75116956],\n",
              "       [0.69939995],\n",
              "       [0.6710544 ],\n",
              "       [0.10790065],\n",
              "       [0.5566236 ],\n",
              "       [0.38202643],\n",
              "       [0.32840216],\n",
              "       [0.77662146],\n",
              "       [0.9624227 ],\n",
              "       [0.66109973],\n",
              "       [0.09569544],\n",
              "       [0.5606272 ],\n",
              "       [0.9167961 ],\n",
              "       [0.5862268 ],\n",
              "       [0.8413491 ],\n",
              "       [0.05463761],\n",
              "       [0.42265916],\n",
              "       [0.15257367],\n",
              "       [0.02253187],\n",
              "       [0.12435582],\n",
              "       [0.75220025],\n",
              "       [0.78909254],\n",
              "       [0.61557233],\n",
              "       [0.6489955 ],\n",
              "       [0.42145252],\n",
              "       [0.8281442 ],\n",
              "       [0.75751114],\n",
              "       [0.951617  ],\n",
              "       [0.69908094],\n",
              "       [0.7618867 ],\n",
              "       [0.04585898],\n",
              "       [0.08062097],\n",
              "       [0.17830208],\n",
              "       [0.21333095],\n",
              "       [0.16911757],\n",
              "       [0.02166912],\n",
              "       [0.8093425 ],\n",
              "       [0.18543193],\n",
              "       [0.0711804 ],\n",
              "       [0.75833124],\n",
              "       [0.06346646],\n",
              "       [0.07250899],\n",
              "       [0.1521959 ],\n",
              "       [0.46518177],\n",
              "       [0.29889023],\n",
              "       [0.7081416 ],\n",
              "       [0.16301769],\n",
              "       [0.08175102],\n",
              "       [0.04272559],\n",
              "       [0.05989447],\n",
              "       [0.01846313],\n",
              "       [0.04850218],\n",
              "       [0.05017278],\n",
              "       [0.05569774],\n",
              "       [0.61906075],\n",
              "       [0.88256836],\n",
              "       [0.72382677],\n",
              "       [0.0122335 ],\n",
              "       [0.02751574],\n",
              "       [0.8168437 ],\n",
              "       [0.8501854 ],\n",
              "       [0.26936132],\n",
              "       [0.02039531],\n",
              "       [0.0510799 ],\n",
              "       [0.6080751 ],\n",
              "       [0.16816637],\n",
              "       [0.23025861],\n",
              "       [0.8349279 ],\n",
              "       [0.09921354],\n",
              "       [0.6887716 ],\n",
              "       [0.04979199],\n",
              "       [0.9497819 ],\n",
              "       [0.6028992 ],\n",
              "       [0.8924514 ],\n",
              "       [0.50917614],\n",
              "       [0.1324442 ],\n",
              "       [0.85597557],\n",
              "       [0.03448069],\n",
              "       [0.325463  ],\n",
              "       [0.05917814],\n",
              "       [0.06719872],\n",
              "       [0.06442198],\n",
              "       [0.64685285],\n",
              "       [0.6394686 ],\n",
              "       [0.03765363],\n",
              "       [0.7553328 ],\n",
              "       [0.5446932 ],\n",
              "       [0.7796891 ],\n",
              "       [0.68907946],\n",
              "       [0.4232474 ],\n",
              "       [0.04160598],\n",
              "       [0.02921984],\n",
              "       [0.7104396 ],\n",
              "       [0.03822261],\n",
              "       [0.08573934],\n",
              "       [0.8451235 ],\n",
              "       [0.11116448],\n",
              "       [0.2645149 ],\n",
              "       [0.095985  ],\n",
              "       [0.32732624],\n",
              "       [0.6567933 ],\n",
              "       [0.9281609 ],\n",
              "       [0.91406727],\n",
              "       [0.85096395],\n",
              "       [0.3210959 ],\n",
              "       [0.5199014 ],\n",
              "       [0.40813667],\n",
              "       [0.21171075],\n",
              "       [0.7252441 ],\n",
              "       [0.32908538],\n",
              "       [0.28893393],\n",
              "       [0.06831646],\n",
              "       [0.18989414],\n",
              "       [0.79314435],\n",
              "       [0.03840145],\n",
              "       [0.02541807],\n",
              "       [0.7330121 ],\n",
              "       [0.9107374 ],\n",
              "       [0.08284566],\n",
              "       [0.06841055],\n",
              "       [0.6673669 ],\n",
              "       [0.30080563],\n",
              "       [0.82646763],\n",
              "       [0.21751279],\n",
              "       [0.55892676],\n",
              "       [0.89062333],\n",
              "       [0.01800597],\n",
              "       [0.9197706 ],\n",
              "       [0.03383839],\n",
              "       [0.0233134 ],\n",
              "       [0.14754021],\n",
              "       [0.84617114],\n",
              "       [0.7322215 ],\n",
              "       [0.86000496],\n",
              "       [0.08630157],\n",
              "       [0.288048  ],\n",
              "       [0.88394904],\n",
              "       [0.07350701],\n",
              "       [0.0800643 ],\n",
              "       [0.8747211 ],\n",
              "       [0.9749564 ],\n",
              "       [0.10847571],\n",
              "       [0.77091736],\n",
              "       [0.07854912],\n",
              "       [0.4941876 ],\n",
              "       [0.83609253],\n",
              "       [0.09730732],\n",
              "       [0.06100085],\n",
              "       [0.01777086],\n",
              "       [0.09905544],\n",
              "       [0.10460314],\n",
              "       [0.11719033],\n",
              "       [0.5645421 ],\n",
              "       [0.750069  ],\n",
              "       [0.08716223],\n",
              "       [0.09646043],\n",
              "       [0.82007957],\n",
              "       [0.8553357 ],\n",
              "       [0.8774141 ],\n",
              "       [0.12586531],\n",
              "       [0.8078673 ],\n",
              "       [0.15026057],\n",
              "       [0.18634218],\n",
              "       [0.24402821],\n",
              "       [0.85948455],\n",
              "       [0.42758864],\n",
              "       [0.22197872],\n",
              "       [0.6929725 ],\n",
              "       [0.09133509],\n",
              "       [0.06395996],\n",
              "       [0.9375141 ],\n",
              "       [0.06517059],\n",
              "       [0.3480445 ],\n",
              "       [0.03377181],\n",
              "       [0.03047886],\n",
              "       [0.17401245],\n",
              "       [0.1018379 ],\n",
              "       [0.06495091],\n",
              "       [0.1175791 ],\n",
              "       [0.24882233],\n",
              "       [0.32969412],\n",
              "       [0.74788946],\n",
              "       [0.84403336],\n",
              "       [0.1015611 ],\n",
              "       [0.42573577],\n",
              "       [0.7188387 ],\n",
              "       [0.8049941 ],\n",
              "       [0.07033205],\n",
              "       [0.06419781],\n",
              "       [0.80147207],\n",
              "       [0.06406602],\n",
              "       [0.45372385],\n",
              "       [0.07349372],\n",
              "       [0.7431513 ],\n",
              "       [0.88810813],\n",
              "       [0.01422885],\n",
              "       [0.19189698],\n",
              "       [0.07250899],\n",
              "       [0.67126155],\n",
              "       [0.07480338],\n",
              "       [0.36772162],\n",
              "       [0.915062  ],\n",
              "       [0.82041824],\n",
              "       [0.16682228],\n",
              "       [0.92090327],\n",
              "       [0.77237463],\n",
              "       [0.9232507 ],\n",
              "       [0.6285533 ],\n",
              "       [0.49845138],\n",
              "       [0.7958717 ],\n",
              "       [0.2405014 ],\n",
              "       [0.7098485 ],\n",
              "       [0.02865359],\n",
              "       [0.10554823],\n",
              "       [0.10636932],\n",
              "       [0.06128171],\n",
              "       [0.07322162],\n",
              "       [0.1440959 ],\n",
              "       [0.0424794 ],\n",
              "       [0.57988036],\n",
              "       [0.56662256],\n",
              "       [0.6380452 ],\n",
              "       [0.48972428],\n",
              "       [0.5282616 ],\n",
              "       [0.8279536 ],\n",
              "       [0.12105897],\n",
              "       [0.07146144],\n",
              "       [0.48905063],\n",
              "       [0.8934337 ],\n",
              "       [0.02197462],\n",
              "       [0.03233147],\n",
              "       [0.53070605],\n",
              "       [0.1271413 ],\n",
              "       [0.034596  ],\n",
              "       [0.7915687 ],\n",
              "       [0.6420341 ],\n",
              "       [0.79200447],\n",
              "       [0.76825583],\n",
              "       [0.2522393 ],\n",
              "       [0.11016399],\n",
              "       [0.03292635],\n",
              "       [0.8319795 ],\n",
              "       [0.4022494 ],\n",
              "       [0.08975372],\n",
              "       [0.62903166],\n",
              "       [0.8395007 ],\n",
              "       [0.74053085],\n",
              "       [0.04354435],\n",
              "       [0.900923  ],\n",
              "       [0.03816175],\n",
              "       [0.23030782],\n",
              "       [0.65415347],\n",
              "       [0.8688938 ],\n",
              "       [0.03228009],\n",
              "       [0.9496746 ],\n",
              "       [0.7538619 ],\n",
              "       [0.02254629],\n",
              "       [0.253992  ],\n",
              "       [0.12188444],\n",
              "       [0.67303646],\n",
              "       [0.7545916 ],\n",
              "       [0.89514667],\n",
              "       [0.76439834],\n",
              "       [0.325463  ],\n",
              "       [0.37775925],\n",
              "       [0.9079833 ],\n",
              "       [0.04960787],\n",
              "       [0.9249358 ],\n",
              "       [0.88572735],\n",
              "       [0.8081406 ],\n",
              "       [0.63189113],\n",
              "       [0.5388988 ],\n",
              "       [0.19435033],\n",
              "       [0.8966891 ],\n",
              "       [0.7118794 ],\n",
              "       [0.7719708 ],\n",
              "       [0.03775394],\n",
              "       [0.80178523],\n",
              "       [0.15036312],\n",
              "       [0.8111185 ],\n",
              "       [0.6308049 ],\n",
              "       [0.04172546],\n",
              "       [0.2442559 ],\n",
              "       [0.15311995],\n",
              "       [0.87088203],\n",
              "       [0.06817579],\n",
              "       [0.8504972 ],\n",
              "       [0.10487053],\n",
              "       [0.03591844],\n",
              "       [0.1653443 ],\n",
              "       [0.10462058],\n",
              "       [0.23760235],\n",
              "       [0.08767617],\n",
              "       [0.7863116 ],\n",
              "       [0.13948008],\n",
              "       [0.1420582 ],\n",
              "       [0.8330636 ],\n",
              "       [0.1478365 ],\n",
              "       [0.05272669],\n",
              "       [0.67360497],\n",
              "       [0.7466031 ],\n",
              "       [0.15898257],\n",
              "       [0.68109465],\n",
              "       [0.2170535 ],\n",
              "       [0.09125125],\n",
              "       [0.07890743],\n",
              "       [0.8434975 ],\n",
              "       [0.02739665],\n",
              "       [0.08321691],\n",
              "       [0.09709337],\n",
              "       [0.76533306],\n",
              "       [0.5111    ],\n",
              "       [0.14843923],\n",
              "       [0.06532201],\n",
              "       [0.01493335],\n",
              "       [0.03850022],\n",
              "       [0.07233524],\n",
              "       [0.9594665 ],\n",
              "       [0.8330636 ],\n",
              "       [0.7375236 ],\n",
              "       [0.05750892],\n",
              "       [0.6299832 ],\n",
              "       [0.22499931],\n",
              "       [0.35529476],\n",
              "       [0.95647573],\n",
              "       [0.7471626 ],\n",
              "       [0.10347632],\n",
              "       [0.9667959 ],\n",
              "       [0.29545218],\n",
              "       [0.5909116 ],\n",
              "       [0.78248847],\n",
              "       [0.40934741],\n",
              "       [0.6468757 ],\n",
              "       [0.41731626],\n",
              "       [0.71119875],\n",
              "       [0.79518974],\n",
              "       [0.15850326],\n",
              "       [0.53629845],\n",
              "       [0.7136963 ],\n",
              "       [0.7679939 ],\n",
              "       [0.03047886],\n",
              "       [0.41639072],\n",
              "       [0.10655999],\n",
              "       [0.9286592 ],\n",
              "       [0.09864342],\n",
              "       [0.5368206 ],\n",
              "       [0.02787274],\n",
              "       [0.63392365],\n",
              "       [0.09000263],\n",
              "       [0.01357999],\n",
              "       [0.56015116],\n",
              "       [0.0126341 ],\n",
              "       [0.86318994],\n",
              "       [0.7480061 ],\n",
              "       [0.98263144],\n",
              "       [0.9650452 ],\n",
              "       [0.77358127],\n",
              "       [0.01583016],\n",
              "       [0.04139668],\n",
              "       [0.07549998],\n",
              "       [0.10044917],\n",
              "       [0.02668288],\n",
              "       [0.07742551],\n",
              "       [0.063353  ],\n",
              "       [0.02116677],\n",
              "       [0.8330636 ],\n",
              "       [0.79740393],\n",
              "       [0.02009091],\n",
              "       [0.6335219 ],\n",
              "       [0.8877144 ],\n",
              "       [0.8585065 ],\n",
              "       [0.571692  ],\n",
              "       [0.94234717],\n",
              "       [0.1015611 ],\n",
              "       [0.88481337],\n",
              "       [0.28456634],\n",
              "       [0.10677272],\n",
              "       [0.8624126 ],\n",
              "       [0.04186171],\n",
              "       [0.9565871 ],\n",
              "       [0.07830817],\n",
              "       [0.04347965],\n",
              "       [0.03839543],\n",
              "       [0.6867324 ],\n",
              "       [0.5745546 ],\n",
              "       [0.83306354],\n",
              "       [0.83606553],\n",
              "       [0.30721372],\n",
              "       [0.813154  ],\n",
              "       [0.83557916],\n",
              "       [0.03422999],\n",
              "       [0.01476321],\n",
              "       [0.7143438 ],\n",
              "       [0.13921314],\n",
              "       [0.88301   ],\n",
              "       [0.16379413],\n",
              "       [0.8968555 ],\n",
              "       [0.80079925],\n",
              "       [0.36672568],\n",
              "       [0.06081572],\n",
              "       [0.19025573],\n",
              "       [0.6649507 ],\n",
              "       [0.15123013],\n",
              "       [0.11245048],\n",
              "       [0.10851556],\n",
              "       [0.25463575],\n",
              "       [0.05913997],\n",
              "       [0.6132452 ],\n",
              "       [0.8572074 ],\n",
              "       [0.35894948],\n",
              "       [0.05046645],\n",
              "       [0.64511466],\n",
              "       [0.3361547 ],\n",
              "       [0.09007484],\n",
              "       [0.36438024],\n",
              "       [0.1714643 ],\n",
              "       [0.23939037],\n",
              "       [0.6569614 ],\n",
              "       [0.90783995],\n",
              "       [0.00735712],\n",
              "       [0.79294264],\n",
              "       [0.12621856],\n",
              "       [0.65849286],\n",
              "       [0.06881073],\n",
              "       [0.40222865],\n",
              "       [0.61420906],\n",
              "       [0.06019235],\n",
              "       [0.7132278 ],\n",
              "       [0.08912843],\n",
              "       [0.656498  ],\n",
              "       [0.8245702 ],\n",
              "       [0.2099038 ],\n",
              "       [0.71002936],\n",
              "       [0.7894936 ],\n",
              "       [0.25011098],\n",
              "       [0.18397152],\n",
              "       [0.77561474],\n",
              "       [0.11572629],\n",
              "       [0.406277  ],\n",
              "       [0.5728542 ],\n",
              "       [0.7818137 ],\n",
              "       [0.09741306],\n",
              "       [0.7797822 ],\n",
              "       [0.5784174 ],\n",
              "       [0.9436407 ],\n",
              "       [0.8334852 ],\n",
              "       [0.04717377],\n",
              "       [0.09269598],\n",
              "       [0.6321992 ],\n",
              "       [0.8918158 ],\n",
              "       [0.06648245],\n",
              "       [0.8330636 ],\n",
              "       [0.7548578 ],\n",
              "       [0.23219803],\n",
              "       [0.22617221],\n",
              "       [0.78836226],\n",
              "       [0.9562596 ],\n",
              "       [0.84608793],\n",
              "       [0.87172556],\n",
              "       [0.02416942],\n",
              "       [0.657283  ],\n",
              "       [0.86292964],\n",
              "       [0.19435033],\n",
              "       [0.09076759],\n",
              "       [0.15520054],\n",
              "       [0.8201808 ],\n",
              "       [0.71897084],\n",
              "       [0.6608135 ],\n",
              "       [0.38963744],\n",
              "       [0.8623802 ],\n",
              "       [0.88007706],\n",
              "       [0.07754335],\n",
              "       [0.06444582],\n",
              "       [0.9301512 ],\n",
              "       [0.06684494],\n",
              "       [0.32077605],\n",
              "       [0.03839543],\n",
              "       [0.55066854],\n",
              "       [0.17077589],\n",
              "       [0.06619909],\n",
              "       [0.19783267],\n",
              "       [0.1292955 ],\n",
              "       [0.0578849 ],\n",
              "       [0.7900953 ],\n",
              "       [0.17314234],\n",
              "       [0.66936636],\n",
              "       [0.02409226],\n",
              "       [0.821256  ],\n",
              "       [0.24298283],\n",
              "       [0.5598194 ],\n",
              "       [0.638729  ],\n",
              "       [0.04722112],\n",
              "       [0.4017281 ],\n",
              "       [0.1762706 ],\n",
              "       [0.15894827],\n",
              "       [0.0530996 ],\n",
              "       [0.09345618],\n",
              "       [0.01538411],\n",
              "       [0.32822675],\n",
              "       [0.0488202 ],\n",
              "       [0.04227501],\n",
              "       [0.7165884 ],\n",
              "       [0.21302775],\n",
              "       [0.0438191 ],\n",
              "       [0.12064606],\n",
              "       [0.72911817],\n",
              "       [0.8326958 ],\n",
              "       [0.73043925],\n",
              "       [0.9340422 ],\n",
              "       [0.12586531],\n",
              "       [0.21734947],\n",
              "       [0.8404943 ],\n",
              "       [0.9017446 ],\n",
              "       [0.03544554],\n",
              "       [0.707731  ],\n",
              "       [0.05753452],\n",
              "       [0.7899381 ],\n",
              "       [0.7583271 ],\n",
              "       [0.91146517],\n",
              "       [0.09080672],\n",
              "       [0.8820336 ],\n",
              "       [0.3591103 ],\n",
              "       [0.04659656],\n",
              "       [0.14233932],\n",
              "       [0.73832756],\n",
              "       [0.6295713 ],\n",
              "       [0.54857785],\n",
              "       [0.4488988 ],\n",
              "       [0.10721266],\n",
              "       [0.04810306],\n",
              "       [0.82523406],\n",
              "       [0.51626986],\n",
              "       [0.01270667],\n",
              "       [0.144117  ],\n",
              "       [0.34471053],\n",
              "       [0.4173911 ],\n",
              "       [0.8979337 ],\n",
              "       [0.19874299],\n",
              "       [0.69044757],\n",
              "       [0.07033163],\n",
              "       [0.0696989 ],\n",
              "       [0.9615216 ],\n",
              "       [0.94418895],\n",
              "       [0.8065504 ],\n",
              "       [0.90257704],\n",
              "       [0.15471002],\n",
              "       [0.83675385],\n",
              "       [0.8518579 ],\n",
              "       [0.2816885 ],\n",
              "       [0.51055914],\n",
              "       [0.02971971],\n",
              "       [0.02807346],\n",
              "       [0.8024303 ],\n",
              "       [0.8593106 ],\n",
              "       [0.08659947],\n",
              "       [0.46034464],\n",
              "       [0.40880933],\n",
              "       [0.45535505],\n",
              "       [0.74899274],\n",
              "       [0.702946  ],\n",
              "       [0.70439243],\n",
              "       [0.7634963 ],\n",
              "       [0.8850815 ],\n",
              "       [0.07535216],\n",
              "       [0.7779267 ],\n",
              "       [0.83723223],\n",
              "       [0.02292737],\n",
              "       [0.3351392 ],\n",
              "       [0.9591136 ],\n",
              "       [0.01758403],\n",
              "       [0.8659027 ],\n",
              "       [0.10160255],\n",
              "       [0.93126667],\n",
              "       [0.9109465 ],\n",
              "       [0.8443129 ],\n",
              "       [0.5909191 ],\n",
              "       [0.10161677],\n",
              "       [0.18344817],\n",
              "       [0.75599366],\n",
              "       [0.19435033],\n",
              "       [0.07210591],\n",
              "       [0.32965696],\n",
              "       [0.8399328 ],\n",
              "       [0.6318921 ],\n",
              "       [0.9373698 ],\n",
              "       [0.9547274 ],\n",
              "       [0.09100139],\n",
              "       [0.40666324],\n",
              "       [0.2099511 ],\n",
              "       [0.9532518 ],\n",
              "       [0.8832104 ],\n",
              "       [0.8370611 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def predict(mail):\n",
        "     y_predicted = model.predict(X_test)\n",
        "     y_predicted = y_predicted.flatten()\n",
        "     y_predicted = np.where(y_predicted > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "l26mh2gUd4Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lNomIfAk1Z2",
        "outputId": "255ad28a-2a35-45b2-d8ea-124df00a8c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8977351 ],\n",
              "       [0.9648032 ],\n",
              "       [0.24423906],\n",
              "       [0.09989417],\n",
              "       [0.5119101 ],\n",
              "       [0.0125874 ],\n",
              "       [0.91329   ],\n",
              "       [0.57473534],\n",
              "       [0.5875761 ],\n",
              "       [0.8790566 ],\n",
              "       [0.34818852],\n",
              "       [0.7017441 ],\n",
              "       [0.92723805],\n",
              "       [0.3718269 ],\n",
              "       [0.1117624 ],\n",
              "       [0.10903108],\n",
              "       [0.6848657 ],\n",
              "       [0.96549946],\n",
              "       [0.95561606],\n",
              "       [0.6706395 ],\n",
              "       [0.02034804],\n",
              "       [0.08365983],\n",
              "       [0.04314968],\n",
              "       [0.8188089 ],\n",
              "       [0.10134268],\n",
              "       [0.05907387],\n",
              "       [0.86684626],\n",
              "       [0.12478039],\n",
              "       [0.04052982],\n",
              "       [0.02739891],\n",
              "       [0.04906222],\n",
              "       [0.07826823],\n",
              "       [0.97009426],\n",
              "       [0.07033205],\n",
              "       [0.10280964],\n",
              "       [0.2905305 ],\n",
              "       [0.2626843 ],\n",
              "       [0.5709429 ],\n",
              "       [0.52675796],\n",
              "       [0.06817579],\n",
              "       [0.11778811],\n",
              "       [0.9802563 ],\n",
              "       [0.9351923 ],\n",
              "       [0.12493089],\n",
              "       [0.2117132 ],\n",
              "       [0.7470538 ],\n",
              "       [0.08679736],\n",
              "       [0.8258853 ],\n",
              "       [0.06689945],\n",
              "       [0.07735839],\n",
              "       [0.4501024 ],\n",
              "       [0.08908314],\n",
              "       [0.06451255],\n",
              "       [0.8250764 ],\n",
              "       [0.78217584],\n",
              "       [0.59462726],\n",
              "       [0.09485453],\n",
              "       [0.22656748],\n",
              "       [0.9516485 ],\n",
              "       [0.5363395 ],\n",
              "       [0.4777041 ],\n",
              "       [0.3736386 ],\n",
              "       [0.5515265 ],\n",
              "       [0.63799655],\n",
              "       [0.12151706],\n",
              "       [0.03191319],\n",
              "       [0.04685163],\n",
              "       [0.93154883],\n",
              "       [0.37909806],\n",
              "       [0.9617157 ],\n",
              "       [0.03153765],\n",
              "       [0.71562284],\n",
              "       [0.09802091],\n",
              "       [0.7900953 ],\n",
              "       [0.93311584],\n",
              "       [0.598724  ],\n",
              "       [0.13483045],\n",
              "       [0.10295779],\n",
              "       [0.05512205],\n",
              "       [0.37496674],\n",
              "       [0.6695311 ],\n",
              "       [0.77065206],\n",
              "       [0.28049943],\n",
              "       [0.88602805],\n",
              "       [0.08931956],\n",
              "       [0.02713448],\n",
              "       [0.01717907],\n",
              "       [0.7060692 ],\n",
              "       [0.8732085 ],\n",
              "       [0.4754979 ],\n",
              "       [0.06817579],\n",
              "       [0.19286174],\n",
              "       [0.40810966],\n",
              "       [0.9075296 ],\n",
              "       [0.06407648],\n",
              "       [0.5999477 ],\n",
              "       [0.10846981],\n",
              "       [0.92857844],\n",
              "       [0.06011164],\n",
              "       [0.21751279],\n",
              "       [0.04045382],\n",
              "       [0.86747074],\n",
              "       [0.25544775],\n",
              "       [0.9401639 ],\n",
              "       [0.35727483],\n",
              "       [0.9279768 ],\n",
              "       [0.24833623],\n",
              "       [0.92624265],\n",
              "       [0.08430913],\n",
              "       [0.79590034],\n",
              "       [0.8456685 ],\n",
              "       [0.05005822],\n",
              "       [0.04785144],\n",
              "       [0.34470809],\n",
              "       [0.04122329],\n",
              "       [0.83454067],\n",
              "       [0.14037925],\n",
              "       [0.06724253],\n",
              "       [0.6742507 ],\n",
              "       [0.2090537 ],\n",
              "       [0.39031002],\n",
              "       [0.1015611 ],\n",
              "       [0.9676331 ],\n",
              "       [0.07960746],\n",
              "       [0.98775804],\n",
              "       [0.9473032 ],\n",
              "       [0.68178356],\n",
              "       [0.5756096 ],\n",
              "       [0.09072912],\n",
              "       [0.66226673],\n",
              "       [0.7356049 ],\n",
              "       [0.2732507 ],\n",
              "       [0.09615126],\n",
              "       [0.10593182],\n",
              "       [0.8191388 ],\n",
              "       [0.06614104],\n",
              "       [0.68303   ],\n",
              "       [0.94858205],\n",
              "       [0.14724296],\n",
              "       [0.163001  ],\n",
              "       [0.6379197 ],\n",
              "       [0.1236605 ],\n",
              "       [0.08391228],\n",
              "       [0.7193365 ],\n",
              "       [0.7583243 ],\n",
              "       [0.6843071 ],\n",
              "       [0.0388076 ],\n",
              "       [0.12586531],\n",
              "       [0.8330636 ],\n",
              "       [0.72818816],\n",
              "       [0.8544141 ],\n",
              "       [0.19046557],\n",
              "       [0.0517469 ],\n",
              "       [0.11301345],\n",
              "       [0.10232183],\n",
              "       [0.07677886],\n",
              "       [0.70498824],\n",
              "       [0.5271883 ],\n",
              "       [0.75116956],\n",
              "       [0.69939995],\n",
              "       [0.6710544 ],\n",
              "       [0.10790065],\n",
              "       [0.5566236 ],\n",
              "       [0.38202643],\n",
              "       [0.32840216],\n",
              "       [0.77662146],\n",
              "       [0.9624227 ],\n",
              "       [0.66109973],\n",
              "       [0.09569544],\n",
              "       [0.5606272 ],\n",
              "       [0.9167961 ],\n",
              "       [0.5862268 ],\n",
              "       [0.8413491 ],\n",
              "       [0.05463761],\n",
              "       [0.42265916],\n",
              "       [0.15257367],\n",
              "       [0.02253187],\n",
              "       [0.12435582],\n",
              "       [0.75220025],\n",
              "       [0.78909254],\n",
              "       [0.61557233],\n",
              "       [0.6489955 ],\n",
              "       [0.42145252],\n",
              "       [0.8281442 ],\n",
              "       [0.75751114],\n",
              "       [0.951617  ],\n",
              "       [0.69908094],\n",
              "       [0.7618867 ],\n",
              "       [0.04585898],\n",
              "       [0.08062097],\n",
              "       [0.17830208],\n",
              "       [0.21333095],\n",
              "       [0.16911757],\n",
              "       [0.02166912],\n",
              "       [0.8093425 ],\n",
              "       [0.18543193],\n",
              "       [0.0711804 ],\n",
              "       [0.75833124],\n",
              "       [0.06346646],\n",
              "       [0.07250899],\n",
              "       [0.1521959 ],\n",
              "       [0.46518177],\n",
              "       [0.29889023],\n",
              "       [0.7081416 ],\n",
              "       [0.16301769],\n",
              "       [0.08175102],\n",
              "       [0.04272559],\n",
              "       [0.05989447],\n",
              "       [0.01846313],\n",
              "       [0.04850218],\n",
              "       [0.05017278],\n",
              "       [0.05569774],\n",
              "       [0.61906075],\n",
              "       [0.88256836],\n",
              "       [0.72382677],\n",
              "       [0.0122335 ],\n",
              "       [0.02751574],\n",
              "       [0.8168437 ],\n",
              "       [0.8501854 ],\n",
              "       [0.26936132],\n",
              "       [0.02039531],\n",
              "       [0.0510799 ],\n",
              "       [0.6080751 ],\n",
              "       [0.16816637],\n",
              "       [0.23025861],\n",
              "       [0.8349279 ],\n",
              "       [0.09921354],\n",
              "       [0.6887716 ],\n",
              "       [0.04979199],\n",
              "       [0.9497819 ],\n",
              "       [0.6028992 ],\n",
              "       [0.8924514 ],\n",
              "       [0.50917614],\n",
              "       [0.1324442 ],\n",
              "       [0.85597557],\n",
              "       [0.03448069],\n",
              "       [0.325463  ],\n",
              "       [0.05917814],\n",
              "       [0.06719872],\n",
              "       [0.06442198],\n",
              "       [0.64685285],\n",
              "       [0.6394686 ],\n",
              "       [0.03765363],\n",
              "       [0.7553328 ],\n",
              "       [0.5446932 ],\n",
              "       [0.7796891 ],\n",
              "       [0.68907946],\n",
              "       [0.4232474 ],\n",
              "       [0.04160598],\n",
              "       [0.02921984],\n",
              "       [0.7104396 ],\n",
              "       [0.03822261],\n",
              "       [0.08573934],\n",
              "       [0.8451235 ],\n",
              "       [0.11116448],\n",
              "       [0.2645149 ],\n",
              "       [0.095985  ],\n",
              "       [0.32732624],\n",
              "       [0.6567933 ],\n",
              "       [0.9281609 ],\n",
              "       [0.91406727],\n",
              "       [0.85096395],\n",
              "       [0.3210959 ],\n",
              "       [0.5199014 ],\n",
              "       [0.40813667],\n",
              "       [0.21171075],\n",
              "       [0.7252441 ],\n",
              "       [0.32908538],\n",
              "       [0.28893393],\n",
              "       [0.06831646],\n",
              "       [0.18989414],\n",
              "       [0.79314435],\n",
              "       [0.03840145],\n",
              "       [0.02541807],\n",
              "       [0.7330121 ],\n",
              "       [0.9107374 ],\n",
              "       [0.08284566],\n",
              "       [0.06841055],\n",
              "       [0.6673669 ],\n",
              "       [0.30080563],\n",
              "       [0.82646763],\n",
              "       [0.21751279],\n",
              "       [0.55892676],\n",
              "       [0.89062333],\n",
              "       [0.01800597],\n",
              "       [0.9197706 ],\n",
              "       [0.03383839],\n",
              "       [0.0233134 ],\n",
              "       [0.14754021],\n",
              "       [0.84617114],\n",
              "       [0.7322215 ],\n",
              "       [0.86000496],\n",
              "       [0.08630157],\n",
              "       [0.288048  ],\n",
              "       [0.88394904],\n",
              "       [0.07350701],\n",
              "       [0.0800643 ],\n",
              "       [0.8747211 ],\n",
              "       [0.9749564 ],\n",
              "       [0.10847571],\n",
              "       [0.77091736],\n",
              "       [0.07854912],\n",
              "       [0.4941876 ],\n",
              "       [0.83609253],\n",
              "       [0.09730732],\n",
              "       [0.06100085],\n",
              "       [0.01777086],\n",
              "       [0.09905544],\n",
              "       [0.10460314],\n",
              "       [0.11719033],\n",
              "       [0.5645421 ],\n",
              "       [0.750069  ],\n",
              "       [0.08716223],\n",
              "       [0.09646043],\n",
              "       [0.82007957],\n",
              "       [0.8553357 ],\n",
              "       [0.8774141 ],\n",
              "       [0.12586531],\n",
              "       [0.8078673 ],\n",
              "       [0.15026057],\n",
              "       [0.18634218],\n",
              "       [0.24402821],\n",
              "       [0.85948455],\n",
              "       [0.42758864],\n",
              "       [0.22197872],\n",
              "       [0.6929725 ],\n",
              "       [0.09133509],\n",
              "       [0.06395996],\n",
              "       [0.9375141 ],\n",
              "       [0.06517059],\n",
              "       [0.3480445 ],\n",
              "       [0.03377181],\n",
              "       [0.03047886],\n",
              "       [0.17401245],\n",
              "       [0.1018379 ],\n",
              "       [0.06495091],\n",
              "       [0.1175791 ],\n",
              "       [0.24882233],\n",
              "       [0.32969412],\n",
              "       [0.74788946],\n",
              "       [0.84403336],\n",
              "       [0.1015611 ],\n",
              "       [0.42573577],\n",
              "       [0.7188387 ],\n",
              "       [0.8049941 ],\n",
              "       [0.07033205],\n",
              "       [0.06419781],\n",
              "       [0.80147207],\n",
              "       [0.06406602],\n",
              "       [0.45372385],\n",
              "       [0.07349372],\n",
              "       [0.7431513 ],\n",
              "       [0.88810813],\n",
              "       [0.01422885],\n",
              "       [0.19189698],\n",
              "       [0.07250899],\n",
              "       [0.67126155],\n",
              "       [0.07480338],\n",
              "       [0.36772162],\n",
              "       [0.915062  ],\n",
              "       [0.82041824],\n",
              "       [0.16682228],\n",
              "       [0.92090327],\n",
              "       [0.77237463],\n",
              "       [0.9232507 ],\n",
              "       [0.6285533 ],\n",
              "       [0.49845138],\n",
              "       [0.7958717 ],\n",
              "       [0.2405014 ],\n",
              "       [0.7098485 ],\n",
              "       [0.02865359],\n",
              "       [0.10554823],\n",
              "       [0.10636932],\n",
              "       [0.06128171],\n",
              "       [0.07322162],\n",
              "       [0.1440959 ],\n",
              "       [0.0424794 ],\n",
              "       [0.57988036],\n",
              "       [0.56662256],\n",
              "       [0.6380452 ],\n",
              "       [0.48972428],\n",
              "       [0.5282616 ],\n",
              "       [0.8279536 ],\n",
              "       [0.12105897],\n",
              "       [0.07146144],\n",
              "       [0.48905063],\n",
              "       [0.8934337 ],\n",
              "       [0.02197462],\n",
              "       [0.03233147],\n",
              "       [0.53070605],\n",
              "       [0.1271413 ],\n",
              "       [0.034596  ],\n",
              "       [0.7915687 ],\n",
              "       [0.6420341 ],\n",
              "       [0.79200447],\n",
              "       [0.76825583],\n",
              "       [0.2522393 ],\n",
              "       [0.11016399],\n",
              "       [0.03292635],\n",
              "       [0.8319795 ],\n",
              "       [0.4022494 ],\n",
              "       [0.08975372],\n",
              "       [0.62903166],\n",
              "       [0.8395007 ],\n",
              "       [0.74053085],\n",
              "       [0.04354435],\n",
              "       [0.900923  ],\n",
              "       [0.03816175],\n",
              "       [0.23030782],\n",
              "       [0.65415347],\n",
              "       [0.8688938 ],\n",
              "       [0.03228009],\n",
              "       [0.9496746 ],\n",
              "       [0.7538619 ],\n",
              "       [0.02254629],\n",
              "       [0.253992  ],\n",
              "       [0.12188444],\n",
              "       [0.67303646],\n",
              "       [0.7545916 ],\n",
              "       [0.89514667],\n",
              "       [0.76439834],\n",
              "       [0.325463  ],\n",
              "       [0.37775925],\n",
              "       [0.9079833 ],\n",
              "       [0.04960787],\n",
              "       [0.9249358 ],\n",
              "       [0.88572735],\n",
              "       [0.8081406 ],\n",
              "       [0.63189113],\n",
              "       [0.5388988 ],\n",
              "       [0.19435033],\n",
              "       [0.8966891 ],\n",
              "       [0.7118794 ],\n",
              "       [0.7719708 ],\n",
              "       [0.03775394],\n",
              "       [0.80178523],\n",
              "       [0.15036312],\n",
              "       [0.8111185 ],\n",
              "       [0.6308049 ],\n",
              "       [0.04172546],\n",
              "       [0.2442559 ],\n",
              "       [0.15311995],\n",
              "       [0.87088203],\n",
              "       [0.06817579],\n",
              "       [0.8504972 ],\n",
              "       [0.10487053],\n",
              "       [0.03591844],\n",
              "       [0.1653443 ],\n",
              "       [0.10462058],\n",
              "       [0.23760235],\n",
              "       [0.08767617],\n",
              "       [0.7863116 ],\n",
              "       [0.13948008],\n",
              "       [0.1420582 ],\n",
              "       [0.8330636 ],\n",
              "       [0.1478365 ],\n",
              "       [0.05272669],\n",
              "       [0.67360497],\n",
              "       [0.7466031 ],\n",
              "       [0.15898257],\n",
              "       [0.68109465],\n",
              "       [0.2170535 ],\n",
              "       [0.09125125],\n",
              "       [0.07890743],\n",
              "       [0.8434975 ],\n",
              "       [0.02739665],\n",
              "       [0.08321691],\n",
              "       [0.09709337],\n",
              "       [0.76533306],\n",
              "       [0.5111    ],\n",
              "       [0.14843923],\n",
              "       [0.06532201],\n",
              "       [0.01493335],\n",
              "       [0.03850022],\n",
              "       [0.07233524],\n",
              "       [0.9594665 ],\n",
              "       [0.8330636 ],\n",
              "       [0.7375236 ],\n",
              "       [0.05750892],\n",
              "       [0.6299832 ],\n",
              "       [0.22499931],\n",
              "       [0.35529476],\n",
              "       [0.95647573],\n",
              "       [0.7471626 ],\n",
              "       [0.10347632],\n",
              "       [0.9667959 ],\n",
              "       [0.29545218],\n",
              "       [0.5909116 ],\n",
              "       [0.78248847],\n",
              "       [0.40934741],\n",
              "       [0.6468757 ],\n",
              "       [0.41731626],\n",
              "       [0.71119875],\n",
              "       [0.79518974],\n",
              "       [0.15850326],\n",
              "       [0.53629845],\n",
              "       [0.7136963 ],\n",
              "       [0.7679939 ],\n",
              "       [0.03047886],\n",
              "       [0.41639072],\n",
              "       [0.10655999],\n",
              "       [0.9286592 ],\n",
              "       [0.09864342],\n",
              "       [0.5368206 ],\n",
              "       [0.02787274],\n",
              "       [0.63392365],\n",
              "       [0.09000263],\n",
              "       [0.01357999],\n",
              "       [0.56015116],\n",
              "       [0.0126341 ],\n",
              "       [0.86318994],\n",
              "       [0.7480061 ],\n",
              "       [0.98263144],\n",
              "       [0.9650452 ],\n",
              "       [0.77358127],\n",
              "       [0.01583016],\n",
              "       [0.04139668],\n",
              "       [0.07549998],\n",
              "       [0.10044917],\n",
              "       [0.02668288],\n",
              "       [0.07742551],\n",
              "       [0.063353  ],\n",
              "       [0.02116677],\n",
              "       [0.8330636 ],\n",
              "       [0.79740393],\n",
              "       [0.02009091],\n",
              "       [0.6335219 ],\n",
              "       [0.8877144 ],\n",
              "       [0.8585065 ],\n",
              "       [0.571692  ],\n",
              "       [0.94234717],\n",
              "       [0.1015611 ],\n",
              "       [0.88481337],\n",
              "       [0.28456634],\n",
              "       [0.10677272],\n",
              "       [0.8624126 ],\n",
              "       [0.04186171],\n",
              "       [0.9565871 ],\n",
              "       [0.07830817],\n",
              "       [0.04347965],\n",
              "       [0.03839543],\n",
              "       [0.6867324 ],\n",
              "       [0.5745546 ],\n",
              "       [0.83306354],\n",
              "       [0.83606553],\n",
              "       [0.30721372],\n",
              "       [0.813154  ],\n",
              "       [0.83557916],\n",
              "       [0.03422999],\n",
              "       [0.01476321],\n",
              "       [0.7143438 ],\n",
              "       [0.13921314],\n",
              "       [0.88301   ],\n",
              "       [0.16379413],\n",
              "       [0.8968555 ],\n",
              "       [0.80079925],\n",
              "       [0.36672568],\n",
              "       [0.06081572],\n",
              "       [0.19025573],\n",
              "       [0.6649507 ],\n",
              "       [0.15123013],\n",
              "       [0.11245048],\n",
              "       [0.10851556],\n",
              "       [0.25463575],\n",
              "       [0.05913997],\n",
              "       [0.6132452 ],\n",
              "       [0.8572074 ],\n",
              "       [0.35894948],\n",
              "       [0.05046645],\n",
              "       [0.64511466],\n",
              "       [0.3361547 ],\n",
              "       [0.09007484],\n",
              "       [0.36438024],\n",
              "       [0.1714643 ],\n",
              "       [0.23939037],\n",
              "       [0.6569614 ],\n",
              "       [0.90783995],\n",
              "       [0.00735712],\n",
              "       [0.79294264],\n",
              "       [0.12621856],\n",
              "       [0.65849286],\n",
              "       [0.06881073],\n",
              "       [0.40222865],\n",
              "       [0.61420906],\n",
              "       [0.06019235],\n",
              "       [0.7132278 ],\n",
              "       [0.08912843],\n",
              "       [0.656498  ],\n",
              "       [0.8245702 ],\n",
              "       [0.2099038 ],\n",
              "       [0.71002936],\n",
              "       [0.7894936 ],\n",
              "       [0.25011098],\n",
              "       [0.18397152],\n",
              "       [0.77561474],\n",
              "       [0.11572629],\n",
              "       [0.406277  ],\n",
              "       [0.5728542 ],\n",
              "       [0.7818137 ],\n",
              "       [0.09741306],\n",
              "       [0.7797822 ],\n",
              "       [0.5784174 ],\n",
              "       [0.9436407 ],\n",
              "       [0.8334852 ],\n",
              "       [0.04717377],\n",
              "       [0.09269598],\n",
              "       [0.6321992 ],\n",
              "       [0.8918158 ],\n",
              "       [0.06648245],\n",
              "       [0.8330636 ],\n",
              "       [0.7548578 ],\n",
              "       [0.23219803],\n",
              "       [0.22617221],\n",
              "       [0.78836226],\n",
              "       [0.9562596 ],\n",
              "       [0.84608793],\n",
              "       [0.87172556],\n",
              "       [0.02416942],\n",
              "       [0.657283  ],\n",
              "       [0.86292964],\n",
              "       [0.19435033],\n",
              "       [0.09076759],\n",
              "       [0.15520054],\n",
              "       [0.8201808 ],\n",
              "       [0.71897084],\n",
              "       [0.6608135 ],\n",
              "       [0.38963744],\n",
              "       [0.8623802 ],\n",
              "       [0.88007706],\n",
              "       [0.07754335],\n",
              "       [0.06444582],\n",
              "       [0.9301512 ],\n",
              "       [0.06684494],\n",
              "       [0.32077605],\n",
              "       [0.03839543],\n",
              "       [0.55066854],\n",
              "       [0.17077589],\n",
              "       [0.06619909],\n",
              "       [0.19783267],\n",
              "       [0.1292955 ],\n",
              "       [0.0578849 ],\n",
              "       [0.7900953 ],\n",
              "       [0.17314234],\n",
              "       [0.66936636],\n",
              "       [0.02409226],\n",
              "       [0.821256  ],\n",
              "       [0.24298283],\n",
              "       [0.5598194 ],\n",
              "       [0.638729  ],\n",
              "       [0.04722112],\n",
              "       [0.4017281 ],\n",
              "       [0.1762706 ],\n",
              "       [0.15894827],\n",
              "       [0.0530996 ],\n",
              "       [0.09345618],\n",
              "       [0.01538411],\n",
              "       [0.32822675],\n",
              "       [0.0488202 ],\n",
              "       [0.04227501],\n",
              "       [0.7165884 ],\n",
              "       [0.21302775],\n",
              "       [0.0438191 ],\n",
              "       [0.12064606],\n",
              "       [0.72911817],\n",
              "       [0.8326958 ],\n",
              "       [0.73043925],\n",
              "       [0.9340422 ],\n",
              "       [0.12586531],\n",
              "       [0.21734947],\n",
              "       [0.8404943 ],\n",
              "       [0.9017446 ],\n",
              "       [0.03544554],\n",
              "       [0.707731  ],\n",
              "       [0.05753452],\n",
              "       [0.7899381 ],\n",
              "       [0.7583271 ],\n",
              "       [0.91146517],\n",
              "       [0.09080672],\n",
              "       [0.8820336 ],\n",
              "       [0.3591103 ],\n",
              "       [0.04659656],\n",
              "       [0.14233932],\n",
              "       [0.73832756],\n",
              "       [0.6295713 ],\n",
              "       [0.54857785],\n",
              "       [0.4488988 ],\n",
              "       [0.10721266],\n",
              "       [0.04810306],\n",
              "       [0.82523406],\n",
              "       [0.51626986],\n",
              "       [0.01270667],\n",
              "       [0.144117  ],\n",
              "       [0.34471053],\n",
              "       [0.4173911 ],\n",
              "       [0.8979337 ],\n",
              "       [0.19874299],\n",
              "       [0.69044757],\n",
              "       [0.07033163],\n",
              "       [0.0696989 ],\n",
              "       [0.9615216 ],\n",
              "       [0.94418895],\n",
              "       [0.8065504 ],\n",
              "       [0.90257704],\n",
              "       [0.15471002],\n",
              "       [0.83675385],\n",
              "       [0.8518579 ],\n",
              "       [0.2816885 ],\n",
              "       [0.51055914],\n",
              "       [0.02971971],\n",
              "       [0.02807346],\n",
              "       [0.8024303 ],\n",
              "       [0.8593106 ],\n",
              "       [0.08659947],\n",
              "       [0.46034464],\n",
              "       [0.40880933],\n",
              "       [0.45535505],\n",
              "       [0.74899274],\n",
              "       [0.702946  ],\n",
              "       [0.70439243],\n",
              "       [0.7634963 ],\n",
              "       [0.8850815 ],\n",
              "       [0.07535216],\n",
              "       [0.7779267 ],\n",
              "       [0.83723223],\n",
              "       [0.02292737],\n",
              "       [0.3351392 ],\n",
              "       [0.9591136 ],\n",
              "       [0.01758403],\n",
              "       [0.8659027 ],\n",
              "       [0.10160255],\n",
              "       [0.93126667],\n",
              "       [0.9109465 ],\n",
              "       [0.8443129 ],\n",
              "       [0.5909191 ],\n",
              "       [0.10161677],\n",
              "       [0.18344817],\n",
              "       [0.75599366],\n",
              "       [0.19435033],\n",
              "       [0.07210591],\n",
              "       [0.32965696],\n",
              "       [0.8399328 ],\n",
              "       [0.6318921 ],\n",
              "       [0.9373698 ],\n",
              "       [0.9547274 ],\n",
              "       [0.09100139],\n",
              "       [0.40666324],\n",
              "       [0.2099511 ],\n",
              "       [0.9532518 ],\n",
              "       [0.8832104 ],\n",
              "       [0.8370611 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(mail):\n",
        "     y_predicted = model.predict(X_test)\n",
        "     y_predicted = y_predicted.flatten()\n",
        "     y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
        "     if abs(y_predicted).any==1: \n",
        "      print (\"Spam\") \n",
        "     else:\n",
        "      print (\"Ham\") "
      ],
      "metadata": {
        "id": "jb1-j1uEhuOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use saved model for prediction"
      ],
      "metadata": {
        "id": "2TkWXH-ndSRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is one factor, which you must to consider. You need to change the learning phase, before converting. It's super important, when you have Dropout or Batch Normalization. Look at 'Keras model to tflite' or 'Problem after converting keras model into Tensorflow pb'"
      ],
      "metadata": {
        "id": "3h0qUrsLuV83"
      }
    }
  ]
}